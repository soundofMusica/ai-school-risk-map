
import json
import math
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Any, Optional, Tuple, List

import numpy as np
import pandas as pd
import streamlit as st
from PIL import Image, ImageDraw, ImageFont

# Optional dependency for drawing
try:
    from streamlit_drawable_canvas import st_canvas
    HAS_CANVAS = True
except Exception:
    HAS_CANVAS = False

from sklearn.model_selection import KFold
from sklearn.metrics import mean_absolute_error, f1_score
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import Ridge
from sklearn.ensemble import RandomForestRegressor
from sklearn.impute import SimpleImputer

# PDF export
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas as pdf_canvas
from reportlab.lib.units import mm


st.set_page_config(page_title="AI í•™êµ ìœ„í—˜ì§€ë„", layout="wide")

APP_DIR = Path(__file__).resolve().parent

DEFAULT_EXCEL = APP_DIR / "AI_í•™êµìœ„í—˜ì§€ë„_êµ¬ì—­_ì²´í¬ë¦¬ìŠ¤íŠ¸.xlsx"
DEFAULT_MAP = APP_DIR / "í•™êµ_ì§€ë„.png"
DEFAULT_POLYGONS = APP_DIR / "polygons.json"


# -------------------------
# Helpers
# -------------------------
def safe_read_excel(xlsx_path: Path) -> Tuple[pd.DataFrame, pd.DataFrame]:
    xls = pd.ExcelFile(xlsx_path)
    # Try common sheet names
    zone_sheet = None
    checklist_sheet = None
    for name in xls.sheet_names:
        low = name.lower()
        if "zone" in low:
            zone_sheet = name
        if "checklist" in low:
            checklist_sheet = name
    if zone_sheet is None:
        zone_sheet = xls.sheet_names[0]
    if checklist_sheet is None:
        checklist_sheet = xls.sheet_names[-1] if len(xls.sheet_names) > 1 else xls.sheet_names[0]

    zones = pd.read_excel(xlsx_path, sheet_name=zone_sheet)
    checklist = pd.read_excel(xlsx_path, sheet_name=checklist_sheet)

    # Normalize expected columns for zones
    zones = zones.copy()
    # expected columns: zone_id, floor, zone_type, display_name, map_hint, notes, polygon_points
    col_map = {}
    for c in zones.columns:
        lc = str(c).strip().lower()
        if lc in ["zone_id", "id"]:
            col_map[c] = "zone_id"
        elif "floor" in lc or lc in ["ì¸µ", "ì¸µìˆ˜"]:
            col_map[c] = "floor"
        elif "type" in lc or "êµ¬ì—­íƒ€ì…" in lc or lc in ["zone_type"]:
            col_map[c] = "zone_type"
        elif "display" in lc or "í‘œì‹œ" in lc or "name" == lc or "ì´ë¦„" in lc:
            col_map[c] = "display_name"
        elif "hint" in lc or "ì§€ë„" in lc:
            col_map[c] = "map_hint"
        elif "note" in lc or "ë©”ëª¨" in lc:
            col_map[c] = "notes"
        elif "polygon" in lc or "points" in lc:
            col_map[c] = "polygon_points"
    zones.rename(columns=col_map, inplace=True)

    if "zone_id" not in zones.columns:
        # Create a fallback
        zones["zone_id"] = [f"ZONE_{i:03d}" for i in range(len(zones))]
    if "floor" not in zones.columns:
        zones["floor"] = zones["zone_id"].astype(str).str.extract(r"F(\d+)").fillna(0).astype(int)
    if "zone_type" not in zones.columns:
        zones["zone_type"] = "UNKNOWN"
    if "display_name" not in zones.columns:
        zones["display_name"] = zones["zone_id"]
    for col in ["map_hint", "notes", "polygon_points"]:
        if col not in zones.columns:
            zones[col] = ""

    # Checklist normalize
    checklist = checklist.copy()
    c_map = {}
    for c in checklist.columns:
        lc = str(c).strip().lower()
        if "id" == lc or "ì²´í¬" in lc:
            c_map[c] = "check_id"
        elif "ì¹´í…Œê³ ë¦¬" in lc or "category" in lc:
            c_map[c] = "category"
        elif "í•­ëª©" in lc or "item" in lc:
            c_map[c] = "item"
        elif "ì´ìœ " in lc or "why" in lc:
            c_map[c] = "why"
        elif "ë°©ë²•" in lc or "how" in lc:
            c_map[c] = "how"
        elif "ì¦ê±°" in lc or "evidence" in lc:
            c_map[c] = "evidence"
        elif "ê´€ë ¨" in lc or "zone" in lc:
            c_map[c] = "related_zone_type"
    checklist.rename(columns=c_map, inplace=True)
    for col in ["check_id", "category", "item", "why", "how", "evidence", "related_zone_type"]:
        if col not in checklist.columns:
            checklist[col] = ""

    # Clean
    zones["floor"] = pd.to_numeric(zones["floor"], errors="coerce").fillna(0).astype(int)
    zones["zone_id"] = zones["zone_id"].astype(str)
    zones["zone_type"] = zones["zone_type"].astype(str)
    zones["display_name"] = zones["display_name"].astype(str)

    return zones, checklist


def load_polygons(json_path: Path) -> Dict[str, Any]:
    if json_path.exists():
        try:
            return json.loads(json_path.read_text(encoding="utf-8"))
        except Exception:
            return {}
    return {}


def save_polygons(json_path: Path, polygons: Dict[str, Any]) -> None:
    json_path.write_text(json.dumps(polygons, ensure_ascii=False, indent=2), encoding="utf-8")


def rect_to_poly(rect: Dict[str, float]) -> List[List[float]]:
    x = float(rect["x"])
    y = float(rect["y"])
    w = float(rect["width"])
    h = float(rect["height"])
    return [[x, y], [x+w, y], [x+w, y+h], [x, y+h]]


def poly_stats(poly: List[List[float]]) -> Dict[str, float]:
    pts = np.array(poly, dtype=float)
    xs, ys = pts[:, 0], pts[:, 1]
    xmin, xmax = xs.min(), xs.max()
    ymin, ymax = ys.min(), ys.max()
    w = max(1e-6, xmax - xmin)
    h = max(1e-6, ymax - ymin)
    area = float(w * h)  # rectangle-like area proxy
    cx, cy = float(xs.mean()), float(ys.mean())
    aspect = float(w / h) if h > 1e-6 else 1.0
    return {"cx": cx, "cy": cy, "w": float(w), "h": float(h), "area": area, "aspect": aspect}


def value_to_color(v: float, vmin: float, vmax: float) -> Tuple[int, int, int, int]:
    # Simple red colormap with alpha
    if vmax <= vmin:
        t = 0.0
    else:
        t = (v - vmin) / (vmax - vmin)
        t = float(np.clip(t, 0.0, 1.0))
    r = int(255 * t + 80 * (1 - t))
    g = int(80 * (1 - t))
    b = int(80 * (1 - t))
    a = int(140)  # alpha
    return (r, g, b, a)


def draw_overlay(img: Image.Image, zones: pd.DataFrame, polygons: Dict[str, Any], score_col: str) -> Image.Image:
    base = img.convert("RGBA").copy()
    overlay = Image.new("RGBA", base.size, (0, 0, 0, 0))
    d = ImageDraw.Draw(overlay)

    # Gather valid scores
    valid = zones[score_col].dropna()
    if len(valid) == 0:
        vmin, vmax = 0.0, 100.0
    else:
        vmin, vmax = float(valid.min()), float(valid.max())

    for _, row in zones.iterrows():
        zid = row["zone_id"]
        if zid not in polygons:
            continue
        poly = polygons[zid].get("poly")
        if not poly:
            continue
        try:
            pts = [(float(x), float(y)) for x, y in poly]
        except Exception:
            continue
        v = row.get(score_col, np.nan)
        if pd.isna(v):
            continue
        color = value_to_color(float(v), vmin, vmax)
        d.polygon(pts, fill=color, outline=(255, 255, 255, 200))

    combined = Image.alpha_composite(base, overlay)
    return combined


def ensure_label_columns(zones: pd.DataFrame) -> pd.DataFrame:
    zones = zones.copy()
    # Label columns the user can fill from survey/simulation
    if "risk_label" not in zones.columns:
        zones["risk_label"] = np.nan  # 0~100
    if "scenario" not in zones.columns:
        zones["scenario"] = "ê¸°ë³¸(ì •ì „)"
    # Optional feature inputs
    for col in ["survey_darkness", "survey_confusion", "survey_confidence", "sim_congestion"]:
        if col not in zones.columns:
            zones[col] = np.nan
    return zones


def build_feature_table(zones: pd.DataFrame, polygons: Dict[str, Any]) -> pd.DataFrame:
    zones = zones.copy()
    # Geometry-derived features
    geom = []
    for zid in zones["zone_id"].tolist():
        if zid in polygons and polygons[zid].get("poly"):
            stats = poly_stats(polygons[zid]["poly"])
        else:
            stats = {"cx": np.nan, "cy": np.nan, "w": np.nan, "h": np.nan, "area": np.nan, "aspect": np.nan}
        stats["zone_id"] = zid
        geom.append(stats)
    geom_df = pd.DataFrame(geom)
    zones = zones.merge(geom_df, on="zone_id", how="left")

    # Basic engineered features
    zones["floor"] = pd.to_numeric(zones["floor"], errors="coerce").fillna(0).astype(int)
    zones["has_polygon"] = zones["area"].notna().astype(int)

    # Feature set (keep small + explainable)
    keep = [
        "zone_id", "floor", "zone_type",
        "cx", "cy", "area", "aspect",
        "survey_darkness", "survey_confusion", "survey_confidence", "sim_congestion",
        "risk_label", "scenario"
    ]
    for c in keep:
        if c not in zones.columns:
            zones[c] = np.nan
    return zones[keep]


@dataclass
class TrainedModel:
    rf: Any
    ridge: Any
    preprocessor: Any
    feature_names: List[str]
    mae_cv: Optional[float] = None


def train_models(df: pd.DataFrame) -> Optional[TrainedModel]:
    # Train on rows with risk_label
    train_df = df[df["risk_label"].notna()].copy()
    if len(train_df) < 10:
        return None

    X = train_df.drop(columns=["risk_label"])
    y = train_df["risk_label"].astype(float)

    num_cols = ["floor", "cx", "cy", "area", "aspect", "survey_darkness", "survey_confusion", "survey_confidence", "sim_congestion"]
    cat_cols = ["zone_type", "scenario"]

    pre = ColumnTransformer(
        transformers=[
            ("num", Pipeline([("imp", SimpleImputer(strategy="median"))]), num_cols),
            ("cat", Pipeline([("imp", SimpleImputer(strategy="most_frequent")),
                              ("oh", OneHotEncoder(handle_unknown="ignore"))]), cat_cols),
        ],
        remainder="drop"
    )

    rf = RandomForestRegressor(n_estimators=300, random_state=42)
    ridge = Ridge(alpha=1.0, random_state=42)

    rf_pipe = Pipeline([("pre", pre), ("model", rf)])
    ridge_pipe = Pipeline([("pre", pre), ("model", ridge)])

    # CV (MAE)
    kf = KFold(n_splits=min(5, len(train_df)), shuffle=True, random_state=42)
    maes = []
    for tr, te in kf.split(train_df):
        Xtr, Xte = X.iloc[tr], X.iloc[te]
        ytr, yte = y.iloc[tr], y.iloc[te]
        rf_pipe.fit(Xtr, ytr)
        pred = rf_pipe.predict(Xte)
        maes.append(mean_absolute_error(yte, pred))
    mae_cv = float(np.mean(maes))

    # Fit final
    rf_pipe.fit(X, y)
    ridge_pipe.fit(X, y)

    # Get feature names for ridge explanation
    oh = ridge_pipe.named_steps["pre"].named_transformers_["cat"].named_steps["oh"]
    cat_feature_names = list(oh.get_feature_names_out(["zone_type", "scenario"]))
    feature_names = [
        "floor", "cx", "cy", "area", "aspect",
        "survey_darkness", "survey_confusion", "survey_confidence", "sim_congestion",
        *cat_feature_names
    ]
    return TrainedModel(rf=rf_pipe, ridge=ridge_pipe, preprocessor=pre, feature_names=feature_names, mae_cv=mae_cv)


def explain_zone(model: TrainedModel, row: pd.Series) -> List[Tuple[str, float]]:
    # Use ridge (linear) to compute contributions: coef * x
    # Build a single-row DF aligned with training columns
    single = row.to_frame().T.copy()
    X = single.drop(columns=["risk_label"], errors="ignore")
    # Transform using ridge pipeline
    pre = model.ridge.named_steps["pre"]
    Xt = pre.transform(X)
    # Ridge coefficients
    coefs = model.ridge.named_steps["model"].coef_
    # Contributions
    contrib = (Xt.toarray() if hasattr(Xt, "toarray") else Xt) * coefs
    contrib = contrib.flatten()
    pairs = list(zip(model.feature_names, contrib))
    pairs.sort(key=lambda x: abs(x[1]), reverse=True)
    return pairs[:6]


# -------------------------
# UI
# -------------------------
st.title("ğŸ« AI í™œìš© í•™êµ ë‚´ë¶€ ìœ„í—˜ì§€ë„ (ì •ì „/ì¬ë‚œ ëŒ€ì‘)")

with st.sidebar:
    st.header("ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°")
    excel_up = st.file_uploader("êµ¬ì—­/ì²´í¬ë¦¬ìŠ¤íŠ¸ ì—‘ì…€ ì—…ë¡œë“œ(.xlsx)", type=["xlsx"])
    map_up = st.file_uploader("ì§€ë„ ì´ë¯¸ì§€ ì—…ë¡œë“œ(.png/.jpg)", type=["png", "jpg", "jpeg"])
    poly_up = st.file_uploader("êµ¬ì—­ í´ë¦¬ê³¤ JSON ì—…ë¡œë“œ(ì„ íƒ)", type=["json"])
    st.divider()
    st.caption("â€» 2~3ì£¼ MVPìš©: êµ¬ì—­ì€ ì§ì ‘ ì‚¬ê°í˜•ìœ¼ë¡œ ì°ì–´ë„ ì¶©ë¶„í•©ë‹ˆë‹¤.")

# Load data
if excel_up is not None:
    excel_path = Path("uploaded.xlsx")
    excel_path.write_bytes(excel_up.getvalue())
else:
    excel_path = DEFAULT_EXCEL

zones_df, checklist_df = safe_read_excel(excel_path)
zones_df = ensure_label_columns(zones_df)

# Load image
if map_up is not None:
    map_path = Path("uploaded_map.png")
    map_path.write_bytes(map_up.getvalue())
else:
    map_path = DEFAULT_MAP

if map_path.exists():
    base_img = Image.open(map_path).convert("RGBA")
else:
    base_img = Image.new("RGBA", (1400, 900), (245, 245, 245, 255))

# Load polygons
if poly_up is not None:
    polygons = json.loads(poly_up.getvalue().decode("utf-8"))
else:
    polygons = load_polygons(DEFAULT_POLYGONS)

# Session state init
if "polygons" not in st.session_state:
    st.session_state["polygons"] = polygons
if "zones_edit" not in st.session_state:
    st.session_state["zones_edit"] = zones_df

polygons = st.session_state["polygons"]
zones_df = st.session_state["zones_edit"]

# Floor selection
floors = sorted([f for f in zones_df["floor"].unique().tolist() if int(f) >= 0])
selected_floor = st.sidebar.selectbox("ì¸µ ì„ íƒ", floors, index=0 if floors else 0)
scenario = st.sidebar.selectbox("ì‹œë‚˜ë¦¬ì˜¤", ["ê¸°ë³¸(ì •ì „)", "ì‰¬ëŠ”ì‹œê°„ ì •ì „(í˜¼ì¡)", "ì „êµ ëŒ€í”¼ ì •ì „(ë°©ì†¡ ë¶ˆì•ˆì •)"])

zones_df["scenario"] = scenario
floor_zones = zones_df[zones_df["floor"] == selected_floor].copy()

tabs = st.tabs(["1) ì§€ë„/êµ¬ì—­ ì„¤ì •", "2) ìœ„í—˜ì§€ë„ ë³´ê¸°", "3) ê·¼ê±°(ì„¤ëª…) ë³´ê¸°", "4) ì²´í¬ë¦¬ìŠ¤íŠ¸/ì¸ì‡„"])

# -------------------------
# Tab 1: Map & Zones
# -------------------------
with tabs[0]:
    st.subheader("1) ì§€ë„ ì—…ë¡œë“œ/ë¶ˆëŸ¬ì˜¤ê¸° + ì¸µ ì„ íƒ + êµ¬ì—­(Zone) ì°ê¸°")

    colA, colB = st.columns([1.3, 1])
    with colA:
        st.write("**í˜„ì¬ ì§€ë„ ë¯¸ë¦¬ë³´ê¸°**")
        st.image(base_img, use_container_width=True)

        if not HAS_CANVAS:
            st.warning("ê·¸ë¦¬ê¸° ê¸°ëŠ¥(ìº”ë²„ìŠ¤)ì„ ì“°ë ¤ë©´ `streamlit-drawable-canvas`ê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txt ì„¤ì¹˜ í›„ ì‹¤í–‰í•˜ì„¸ìš”.")
        else:
            st.markdown("### êµ¬ì—­ ì‚¬ê°í˜• ì°ê¸°(ë¹ ë¥¸ MVP)")
            zone_pick = st.selectbox("êµ¬ì—­ ì„ íƒ(ì°ì„ ëŒ€ìƒ)", floor_zones["zone_id"].tolist(),
                                     format_func=lambda zid: f"{zid} â€” {floor_zones.set_index('zone_id').loc[zid, 'display_name']}")
            drawing_mode = st.radio("ê·¸ë¦¬ê¸° ëª¨ë“œ", ["rect"], horizontal=True)
            st.caption("íŒ: êµì‹¤ì€ ë°•ìŠ¤ 1ê°œë¡œ, ë³µë„ëŠ” ê¸¸ê²Œ 1~3êµ¬ê°„ë§Œ ë‚˜ëˆ ë„ ë©ë‹ˆë‹¤.")

            canvas_res = st_canvas(
                fill_color="rgba(255, 0, 0, 0.15)",
                stroke_width=2,
                stroke_color="#FF0000",
                background_image=base_img,
                update_streamlit=True,
                height=min(950, base_img.size[1]),
                width=min(1400, base_img.size[0]),
                drawing_mode=drawing_mode,
                key=f"canvas_{selected_floor}",
            )

            if canvas_res.json_data is not None and len(canvas_res.json_data.get("objects", [])) > 0:
                # Use the last drawn object
                obj = canvas_res.json_data["objects"][-1]
                if obj.get("type") == "rect":
                    poly = rect_to_poly(obj)
                    polygons[zone_pick] = {"poly": poly, "source": "rect"}
                    st.success(f"{zone_pick} êµ¬ì—­ ì €ì¥ ì™„ë£Œ! (ì‚¬ê°í˜•)")
                    st.session_state["polygons"] = polygons

            # Save buttons
            c1, c2, c3 = st.columns(3)
            with c1:
                if st.button("í´ë¦¬ê³¤ ì €ì¥(ë¡œì»¬ íŒŒì¼)"):
                    save_polygons(DEFAULT_POLYGONS, polygons)
                    st.toast("polygons.json ì €ì¥ ì™„ë£Œ", icon="âœ…")
            with c2:
                st.download_button(
                    "í´ë¦¬ê³¤ JSON ë‹¤ìš´ë¡œë“œ",
                    data=json.dumps(polygons, ensure_ascii=False, indent=2).encode("utf-8"),
                    file_name="polygons.json",
                    mime="application/json",
                )
            with c3:
                st.metric("ì´ ì¸µ ì™„ë£Œ êµ¬ì—­", f"{sum(1 for z in floor_zones['zone_id'] if z in polygons)}/{len(floor_zones)}")

    with colB:
        st.markdown("### êµ¬ì—­ í…Œì´ë¸”(ë¼ë²¨/ì…ë ¥ê°’ë„ ê°™ì´ ê´€ë¦¬)")
        editable_cols = ["zone_id", "display_name", "zone_type", "floor", "risk_label",
                         "survey_darkness", "survey_confusion", "survey_confidence", "sim_congestion",
                         "map_hint", "notes"]
        shown = zones_df[editable_cols].copy()
        edited = st.data_editor(
            shown,
            use_container_width=True,
            num_rows="fixed",
            hide_index=True,
            column_config={
                "risk_label": st.column_config.NumberColumn("risk_label (0~100)", min_value=0, max_value=100, step=1),
                "survey_darkness": st.column_config.NumberColumn("ì„¤ë¬¸:ì–´ë‘ì›€(1~5)", min_value=1, max_value=5, step=1),
                "survey_confusion": st.column_config.NumberColumn("ì„¤ë¬¸:í˜¼ë€(1~5)", min_value=1, max_value=5, step=1),
                "survey_confidence": st.column_config.NumberColumn("ì„¤ë¬¸:ê¸¸ì°¾ê¸° ìì‹ ê°(1~5)", min_value=1, max_value=5, step=1),
                "sim_congestion": st.column_config.NumberColumn("ì‹œë®¬:í˜¼ì¡(0~1)", min_value=0.0, max_value=1.0, step=0.01),
            },
        )
        # Persist edits
        st.session_state["zones_edit"] = edited.merge(zones_df.drop(columns=editable_cols), left_on="zone_id", right_on="zone_id", how="left")

        st.download_button(
            "êµ¬ì—­ ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ",
            data=st.session_state["zones_edit"].to_csv(index=False).encode("utf-8-sig"),
            file_name="zones_with_labels.csv",
            mime="text/csv",
        )

# -------------------------
# Tab 2: Risk Map
# -------------------------
with tabs[1]:
    st.subheader("2) ìœ„í—˜ í‘œì‹œ(íˆíŠ¸ë§µ/êµ¬ì—­ ìƒ‰ì¹ )")

    feat_df = build_feature_table(zones_df, polygons)

    model = train_models(feat_df)
    if model is None:
        st.info("ëª¨ë¸ í•™ìŠµì„ ìœ„í•´ì„œëŠ” **risk_label(0~100)** ì´ ìµœì†Œ 10ê°œ ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤. (ì„¤ë¬¸ í‰ê· ì´ë‚˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ ì ìˆ˜ë¡œ ì±„ì›Œ ë„£ìœ¼ì„¸ìš”)")
        st.write("í˜„ì¬ ë¼ë²¨ ìˆ˜:", int(feat_df["risk_label"].notna().sum()))
        # Still show map with labeled zones only
        temp = zones_df.copy()
        temp["pred_score"] = temp["risk_label"]
        img2 = draw_overlay(base_img, temp[temp["floor"] == selected_floor], polygons, "pred_score")
        st.image(img2, use_container_width=True)
    else:
        st.success(f"ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! (êµì°¨ê²€ì¦ MAE â‰ˆ {model.mae_cv:.1f})")
        # Predict for all zones
        X_all = feat_df.drop(columns=["risk_label"])
        preds = model.rf.predict(X_all)
        zones_df = zones_df.copy()
        zones_df["pred_score"] = preds
        st.session_state["zones_edit"] = zones_df  # persist

        floor_pred = zones_df[zones_df["floor"] == selected_floor].copy()
        img2 = draw_overlay(base_img, floor_pred, polygons, "pred_score")

        c1, c2 = st.columns([1.4, 1])
        with c1:
            st.image(img2, use_container_width=True)
        with c2:
            st.markdown("### ìœ„í—˜ Top 10")
            top = floor_pred.dropna(subset=["pred_score"]).sort_values("pred_score", ascending=False).head(10)
            st.dataframe(top[["zone_id", "display_name", "zone_type", "pred_score"]], use_container_width=True, hide_index=True)

            st.markdown("### ë“±ê¸‰(ì•ˆì „/ì£¼ì˜/ìœ„í—˜)")
            if top["pred_score"].notna().any():
                q1, q2 = np.quantile(floor_pred["pred_score"].dropna(), [0.6, 0.85])
                def cls(v):
                    if v >= q2: return "ìœ„í—˜"
                    if v >= q1: return "ì£¼ì˜"
                    return "ì•ˆì „"
                floor_pred["risk_class"] = floor_pred["pred_score"].apply(cls)
                st.dataframe(floor_pred[["zone_id", "display_name", "risk_class", "pred_score"]].sort_values("pred_score", ascending=False).head(15),
                             use_container_width=True, hide_index=True)

# -------------------------
# Tab 3: Explanation
# -------------------------
with tabs[2]:
    st.subheader("3) êµ¬ì—­ í´ë¦­/ì„ íƒ â†’ ê·¼ê±° ì„¤ëª…(ì„¤ëª…ê°€ëŠ¥)")

    feat_df = build_feature_table(st.session_state["zones_edit"], polygons)
    model = train_models(feat_df)

    pick = st.selectbox("ê·¼ê±°ë¥¼ ë³¼ êµ¬ì—­ ì„ íƒ", floor_zones["zone_id"].tolist(),
                        format_func=lambda zid: f"{zid} â€” {floor_zones.set_index('zone_id').loc[zid, 'display_name']}")

    row = feat_df[feat_df["zone_id"] == pick].iloc[0]
    zrow = st.session_state["zones_edit"].set_index("zone_id").loc[pick]

    # Display summary
    c1, c2 = st.columns([1.2, 1])
    with c1:
        st.markdown("### êµ¬ì—­ ìš”ì•½")
        st.write({
            "zone_id": pick,
            "ì´ë¦„": str(zrow["display_name"]),
            "íƒ€ì…": str(zrow["zone_type"]),
            "ì¸µ": int(zrow["floor"]),
            "risk_label(ìˆë‹¤ë©´)": None if pd.isna(zrow.get("risk_label", np.nan)) else float(zrow["risk_label"]),
            "pred_score(ìˆë‹¤ë©´)": None if pd.isna(zrow.get("pred_score", np.nan)) else float(zrow["pred_score"]),
        })

        st.markdown("### ì…ë ¥ ë°ì´í„°(ê·¼ê±°ìš©)")
        evidence = {
            "ì„¤ë¬¸-ì–´ë‘ì›€(1~5)": None if pd.isna(zrow.get("survey_darkness", np.nan)) else float(zrow["survey_darkness"]),
            "ì„¤ë¬¸-í˜¼ë€(1~5)": None if pd.isna(zrow.get("survey_confusion", np.nan)) else float(zrow["survey_confusion"]),
            "ì„¤ë¬¸-ê¸¸ì°¾ê¸° ìì‹ ê°(1~5)": None if pd.isna(zrow.get("survey_confidence", np.nan)) else float(zrow["survey_confidence"]),
            "ì‹œë®¬-í˜¼ì¡(0~1)": None if pd.isna(zrow.get("sim_congestion", np.nan)) else float(zrow["sim_congestion"]),
        }
        st.json(evidence, expanded=False)

    with c2:
        st.markdown("### ì§€ë„ì—ì„œ ìœ„ì¹˜ í•˜ì´ë¼ì´íŠ¸")
        # Create a highlight image
        temp = st.session_state["zones_edit"].copy()
        temp["tmp_score"] = 0
        hi = draw_overlay(base_img, temp[temp["floor"] == selected_floor], polygons, "tmp_score")  # just outlines
        hi = hi.convert("RGBA")
        draw = ImageDraw.Draw(hi, "RGBA")
        if pick in polygons and polygons[pick].get("poly"):
            pts = [(float(x), float(y)) for x, y in polygons[pick]["poly"]]
            draw.polygon(pts, outline=(0, 255, 255, 220), width=4)
        st.image(hi, use_container_width=True)

    st.markdown("### ì™œ ìœ„í—˜í•œê°€? (ì„¤ëª… ë¬¸êµ¬ ìë™ ìƒì„±)")

    # Template explanations using available evidence
    def sentence_templates(z: pd.Series) -> List[str]:
        parts = []
        # Use filled inputs as "data grounds"
        if not pd.isna(z.get("survey_darkness", np.nan)) and z["survey_darkness"] >= 4:
            parts.append("ì„¤ë¬¸ì—ì„œ â€˜ì •ì „ ì‹œ ì–´ë‘ì›€â€™ ì ìˆ˜ê°€ ë†’ì•˜ìŠµë‹ˆë‹¤.")
        if not pd.isna(z.get("survey_confusion", np.nan)) and z["survey_confusion"] >= 4:
            parts.append("ì„¤ë¬¸ì—ì„œ â€˜í˜¼ë€/ìš°ì™•ì¢Œì™•â€™ ê°€ëŠ¥ì„±ì´ ë†’ê²Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.")
        if not pd.isna(z.get("survey_confidence", np.nan)) and z["survey_confidence"] <= 2:
            parts.append("ì„¤ë¬¸ì—ì„œ â€˜ë¹„ìƒêµ¬ ë°©í–¥ ìì‹ ê°â€™ì´ ë‚®ì•„ ê¸¸ì°¾ê¸° ì‹¤íŒ¨ ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤.")
        if not pd.isna(z.get("sim_congestion", np.nan)) and z["sim_congestion"] >= 0.6:
            parts.append("ì‹œë®¬ë ˆì´ì…˜ì—ì„œ í˜¼ì¡ë„ê°€ ë†’ì€ êµ¬ê°„ìœ¼ë¡œ ì˜ˆì¸¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
        if len(parts) == 0:
            parts.append("í˜„ì¬ ì…ë ¥ ë°ì´í„°ê°€ ë¶€ì¡±í•´, ìœ„ì¹˜/ìœ í˜• ê¸°ë°˜ìœ¼ë¡œ ë³´ìˆ˜ì ìœ¼ë¡œ ì˜ˆì¸¡í–ˆìŠµë‹ˆë‹¤.")
        score = zrow.get("pred_score", np.nan)
        if not pd.isna(score):
            prefix = f"**ì˜ˆì¸¡ ìœ„í—˜ ì ìˆ˜ {score:.0f}/100**: "
        else:
            prefix = "**ìœ„í—˜ ê·¼ê±°**: "
        s1 = prefix + " ".join(parts[:2])
        s2 = "ê·¼ê±° ë°ì´í„°: " + ", ".join([k for k,v in evidence.items() if v is not None]) + " (ì…ë ¥ëœ í•­ëª© ê¸°ì¤€)"
        return [s1, s2]

    for s in sentence_templates(zrow):
        st.write("â€¢ " + s)

    if model is not None:
        st.markdown("### ëª¨ë¸ ê¸°ë°˜ ì„¤ëª…(ìƒìœ„ ê¸°ì—¬ ìš”ì¸)")
        contrib = explain_zone(model, row)
        st.dataframe(pd.DataFrame(contrib, columns=["ìš”ì¸", "ê¸°ì—¬(+) ìœ„í—˜â†‘ / (-) ìœ„í—˜â†“"]).head(6), use_container_width=True, hide_index=True)
        st.caption("â€» ê¸°ì—¬ë„ëŠ” ë‹¨ìˆœ ì„ í˜•ëª¨ë¸(Ridge) ê¸°ì¤€ì´ë©°, ì‹¤ì œ ì˜ˆì¸¡ì€ RandomForest ê²°ê³¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    else:
        st.info("ëª¨ë¸ ì„¤ëª…ì„ ë³´ë ¤ë©´ risk_labelì´ ìµœì†Œ 10ê°œ ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤.")

# -------------------------
# Tab 4: Checklist & Print
# -------------------------
with tabs[3]:
    st.subheader("4) ì¸ì‡„ ê°€ëŠ¥í•œ ì²´í¬ë¦¬ìŠ¤íŠ¸ (ë‹´ì„/í–‰ì •ì‹¤ìš©)")

    st.markdown("### ì²´í¬ë¦¬ìŠ¤íŠ¸(15ê°œ) í™•ì¸/ìˆ˜ì •")
    checklist_edit = st.data_editor(checklist_df, use_container_width=True, hide_index=True, num_rows="fixed")
    st.download_button(
        "ì²´í¬ë¦¬ìŠ¤íŠ¸ CSV ë‹¤ìš´ë¡œë“œ",
        data=checklist_edit.to_csv(index=False).encode("utf-8-sig"),
        file_name="checklist.csv",
        mime="text/csv",
    )

    st.divider()
    st.markdown("### ì¸ì‡„ìš© PDF ìƒì„±")
    st.caption("PDFì—ëŠ” (1) ì¸µ/ì‹œë‚˜ë¦¬ì˜¤, (2) ìœ„í—˜ Top êµ¬ì—­, (3) ì²´í¬ë¦¬ìŠ¤íŠ¸ í•­ëª©(ì²´í¬ë°•ìŠ¤)ì´ ë“¤ì–´ê°‘ë‹ˆë‹¤.")

    zones_now = st.session_state["zones_edit"].copy()
    floor_now = zones_now[zones_now["floor"] == selected_floor].copy()

    # Determine risk values for printing
    score_col = "pred_score" if "pred_score" in floor_now.columns and floor_now["pred_score"].notna().any() else "risk_label"
    topk = floor_now.dropna(subset=[score_col]).sort_values(score_col, ascending=False).head(10)

    def build_pdf_bytes() -> bytes:
        from io import BytesIO
        buf = BytesIO()
        c = pdf_canvas.Canvas(buf, pagesize=A4)
        w, h = A4

        x0 = 18 * mm
        y = h - 18 * mm

        def line(txt, dy=6.5*mm, size=11, bold=False):
            nonlocal y
            c.setFont("Helvetica-Bold" if bold else "Helvetica", size)
            c.drawString(x0, y, txt)
            y -= dy

        line("AI í•™êµ ìœ„í—˜ì§€ë„ ì²´í¬ë¦¬ìŠ¤íŠ¸ (ì¸ì‡„ìš©)", size=16, bold=True, dy=9*mm)
        line(f"- ì¸µ: {selected_floor}F", bold=False)
        line(f"- ì‹œë‚˜ë¦¬ì˜¤: {scenario}", bold=False)
        line(f"- ì ìˆ˜ ê¸°ì¤€: {score_col}", bold=False)
        y -= 3*mm

        line("1) ìœ„í—˜ êµ¬ì—­ Top 10", bold=True, dy=8*mm)
        if len(topk) == 0:
            line("  (ì•„ì§ ë¼ë²¨/ì˜ˆì¸¡ ì ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. risk_labelì„ ì…ë ¥í•˜ì„¸ìš”.)", size=10)
        else:
            for _, r in topk.iterrows():
                line(f"â–¡ {r['zone_id']}  {r['display_name']}  ({float(r[score_col]):.0f}/100)", size=10, dy=6*mm)

        y -= 2*mm
        line("2) ì ê²€ ì²´í¬ë¦¬ìŠ¤íŠ¸(15)", bold=True, dy=8*mm)
        for _, r in checklist_edit.iterrows():
            item = str(r.get("item", "")).strip()
            if not item:
                continue
            # wrap
            text = f"â–¡ {item}"
            # naive wrapping
            max_chars = 55
            if len(text) <= max_chars:
                line(text, size=10, dy=6*mm)
            else:
                line(text[:max_chars], size=10, dy=6*mm)
                line("   " + text[max_chars:], size=10, dy=6*mm)

            if y < 25*mm:
                c.showPage()
                y = h - 18*mm

        y -= 4*mm
        line("ë©”ëª¨:", bold=True, dy=8*mm)
        for _ in range(6):
            line("________________________________________________________________________", size=10, dy=7*mm)

        c.showPage()
        c.save()
        return buf.getvalue()

    pdf_bytes = build_pdf_bytes()
    st.download_button(
        "ì¸ì‡„ìš© ì²´í¬ë¦¬ìŠ¤íŠ¸ PDF ë‹¤ìš´ë¡œë“œ",
        data=pdf_bytes,
        file_name=f"ì²´í¬ë¦¬ìŠ¤íŠ¸_{selected_floor}F.pdf",
        mime="application/pdf",
    )

    st.markdown("#### ì„¤ëª… ë¬¸êµ¬ ì˜ˆì‹œ(ì¸ì‡„ë¬¼/ë³´ê³ ì„œì— ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥)")
    st.write("â€¢ â€œë³¸ ì²´í¬ë¦¬ìŠ¤íŠ¸ëŠ” ì„¤ë¬¸Â·ì‹œë®¬ ê¸°ë°˜ ìœ„í—˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìš°ì„  ì ê²€ êµ¬ì—­ì„ ì œì‹œí•©ë‹ˆë‹¤. (ì‹œë‚˜ë¦¬ì˜¤ë³„ë¡œ ê²°ê³¼ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ)â€")
    st.write("â€¢ â€œì ìˆ˜/ë“±ê¸‰ì€ í•™êµ ë‚´ë¶€ ë°ì´í„°ë¡œ í•™ìŠµí•œ ëª¨ë¸ì˜ ì˜ˆì¸¡ì´ë©°, ë¶ˆí™•ì‹¤ êµ¬ì—­ì€ í˜„ì¥ í™•ì¸ í›„ ì¡°ì¹˜ ì—¬ë¶€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.â€")
